{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407ecbbe",
   "metadata": {},
   "source": [
    "## Parse TfRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9084993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d568f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(file):\n",
    "    feature_description = {\n",
    "        'note': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'note_str': tf.io.FixedLenFeature([], tf.string),\n",
    "        'instrument': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'instrument_str': tf.io.FixedLenFeature([], tf.string),\n",
    "        'pitch': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'velocity': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sample_rate': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'audio': tf.io.FixedLenFeature([64000], tf.float32), # 4 seconds at 16kHz\n",
    "        'qualities': tf.io.FixedLenFeature([10], tf.int64),\n",
    "        'qualities_str': tf.io.VarLenFeature(tf.string),\n",
    "        'instrument_family': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'instrument_family_str': tf.io.FixedLenFeature([], tf.string),\n",
    "        'instrument_source': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'instrument_source_str': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(file, feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214d6bc",
   "metadata": {},
   "source": [
    "## Extract Features and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bae3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115f3e",
   "metadata": {},
   "source": [
    "### Extracting the Features\n",
    "\n",
    "For most of the features, I used all integer values of their representations, and including the entire feature set of qualities (binary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e59519",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "FFT_SIZE = 1024\n",
    "HOP = 256\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8247f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_mat = tf.signal.linear_to_mel_weight_matrix(\n",
    "    num_mel_bins   = N_MELS,\n",
    "    num_spectrogram_bins = FFT_SIZE // 2 + 1,\n",
    "    sample_rate    = SR,\n",
    "    lower_edge_hertz  = 30.0,\n",
    "    upper_edge_hertz  = SR/2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3184ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(example):\n",
    "    # audio features - extract statistical features from raw audio with mel spectrograms\n",
    "    # raw audio is too high dimensional for naive bayes at 16kHz, so must use its statistics with timeframes as features\n",
    "    audio = tf.cast(example['audio'], tf.float32)\n",
    "    \n",
    "    # compute stft\n",
    "    stft = tf.signal.stft(audio, frame_length=FFT_SIZE, frame_step=HOP, fft_length=FFT_SIZE)\n",
    "    spectogram = tf.abs(stft)\n",
    "    mel_spec = tf.tensordot(spectogram, mel_mat, axes=1)\n",
    "    mel_spec.set_shape(spectogram.shape[:-1].concatenate(mel_mat.shape[-1:]))\n",
    "    \n",
    "    # simple log normalization\n",
    "    log_mel_spec = tf.math.log(mel_spec + 1e-6)\n",
    "    \n",
    "    # reduce dimensionality (mean over time axis)\n",
    "    mel = tf.reduce_mean(log_mel_spec, axis=0)\n",
    "\n",
    "    # Final 1D vector: concatenate instead of stack to avoid shape issues\n",
    "    feature_vector = tf.concat([\n",
    "        tf.cast([example['note'],\n",
    "                 example['pitch'],\n",
    "                 example['velocity'],\n",
    "                 example['sample_rate'],\n",
    "                 example['instrument_source']], tf.float32),\n",
    "        mel                                           # 128-D\n",
    "    ], axis=0)\n",
    "    \n",
    "    return feature_vector, example['instrument_family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00aa095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train': 289205,\n",
    "    'valid': 12678,\n",
    "    'test': 4096\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db0fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(path):\n",
    "    dataset = tf.data.TFRecordDataset(path)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for split, size in dataset_sizes.items():\n",
    "        if split in path:\n",
    "            count = size\n",
    "    print(f\"Found {count} examples in dataset\")\n",
    "    \n",
    "    # `map` with parallelization\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # extract features with parallelization\n",
    "    dataset = dataset.map(lambda example: extract_features(example), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # convert the dataset to a NumPy array\n",
    "    X, y = [], []\n",
    "    for features, label in tqdm(dataset, total=count, desc=\"Loading data...\"):\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6064c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord = '../datasets/nsynth-train.tfrecord'\n",
    "valid_tfrecord = '../datasets/nsynth-valid.tfrecord'\n",
    "test_tfrecord = '../datasets/nsynth-test.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627ae0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 289205 examples in dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...: 100%|██████████| 289205/289205 [04:50<00:00, 994.25it/s] \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = process_dataset(train_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfc1687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12678 examples in dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...: 100%|██████████| 12678/12678 [00:10<00:00, 1212.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = process_dataset(valid_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a2f1bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 examples in dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...: 100%|██████████| 4096/4096 [00:03<00:00, 1189.28it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = process_dataset(test_tfrecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f33c0a",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59f564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c7f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hw5\n",
    "def train_model(model, X_train, y_train, model_name):\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4f1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes model...\n",
      "\n",
      "Training Naive Bayes...\n",
      "Training completed in 3.52 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Naive Bayes model...\")\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model = train_model(\n",
    "    nb_model, X_train, y_train, \"Naive Bayes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f3e08",
   "metadata": {},
   "source": [
    "### Evaluate Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2a71573",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = nb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3307b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2638\n",
      "           1       0.00      0.00      0.00       886\n",
      "           2       0.22      0.23      0.22       470\n",
      "           3       0.00      0.00      0.00      2081\n",
      "           4       0.12      0.10      0.11      2404\n",
      "           5       0.13      0.53      0.21       663\n",
      "           6       0.24      0.71      0.36      1598\n",
      "           7       0.00      0.00      0.00       720\n",
      "           8       0.00      0.00      0.00       814\n",
      "          10       0.16      0.95      0.27       404\n",
      "\n",
      "    accuracy                           0.18     12678\n",
      "   macro avg       0.09      0.25      0.12     12678\n",
      "weighted avg       0.07      0.18      0.09     12678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75d917",
   "metadata": {},
   "source": [
    "### Evaluate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba0bd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a06b0e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       843\n",
      "           1       0.00      0.00      0.00       269\n",
      "           2       0.23      0.19      0.21       180\n",
      "           3       0.00      0.00      0.00       652\n",
      "           4       0.12      0.10      0.11       766\n",
      "           5       0.13      0.52      0.21       202\n",
      "           6       0.24      0.73      0.36       502\n",
      "           7       0.00      0.00      0.00       235\n",
      "           8       0.00      0.00      0.00       306\n",
      "          10       0.15      0.91      0.26       141\n",
      "\n",
      "    accuracy                           0.17      4096\n",
      "   macro avg       0.09      0.24      0.11      4096\n",
      "weighted avg       0.07      0.17      0.09      4096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\School\\Spring 2025\\CSCI 4930\\ML_Project_2025\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
